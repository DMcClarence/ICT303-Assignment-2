{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%pip install torch torchvision --index-url https://download.pytorch.org/whl/cu129\n",
    "%pip install matplotlib\n",
    "%pip install numpy\n",
    "%pip install tensorboard\n",
    "%pip install scikit-learn"
   ],
   "id": "924ddecfdff506ee",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-24T08:21:49.613831Z",
     "start_time": "2025-10-24T08:21:41.620703Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Set Up\n",
    "import os\n",
    "import torch\n",
    "\n",
    "from torchvision import transforms\n",
    "import torchvision\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from DataLoader import DataLoader\n",
    "from CNN import CNN\n",
    "from Trainer import Trainer\n",
    "\n",
    "def img_show(img):\n",
    "    img = img / 2 + 0.5 # unnormalize\n",
    "    np_img = img.cpu().numpy()\n",
    "    plt.imshow(np.transpose(np_img, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "train_transform = transforms.Compose([transforms.Resize((224, 224)),\n",
    "                                      transforms.RandomHorizontalFlip(),\n",
    "                                      transforms.RandomVerticalFlip(),\n",
    "                                      transforms.RandomRotation(180),\n",
    "                                      transforms.RandomAdjustSharpness(0), # Randomly Blur Image\n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "test_transform = transforms.Compose([transforms.Resize((224, 224)),\n",
    "                                     transforms.ToTensor(),\n",
    "                                     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ],
   "id": "ca81adf861eac5b7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-24T08:21:52.806494Z",
     "start_time": "2025-10-24T08:21:49.681392Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_set = DataLoader(data_dir=os.getcwd() + \"/fire_dataset\", trans_width=224, trans_height=224).load(directory=\"/train\", transform=train_transform, batch_size=32, shuffle=True, workers=2)\n",
    "valid_set = DataLoader(data_dir=os.getcwd() + \"/fire_dataset\", trans_width=224, trans_height=224).load(transform=test_transform, batch_size=32, shuffle=True, workers=2)\n",
    "test_set = DataLoader(data_dir=os.getcwd() + \"/fire_dataset\", trans_width=224, trans_height=224).load(transform=test_transform, batch_size=32, shuffle=False, workers=2)\n",
    "model = CNN(log_dir=os.getcwd()+\"/CNN\", lr=1e-4).to(device)\n",
    "trainer = Trainer(log_dir=os.getcwd()+\"/CNN\", n_epochs=2, device=device)"
   ],
   "id": "a5a655cad7821e19",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-24T08:21:52.831293Z",
     "start_time": "2025-10-24T08:21:52.817495Z"
    }
   },
   "cell_type": "code",
   "source": "writer = SummaryWriter(log_dir=os.getcwd()+\"/CNN\")",
   "id": "5accc0822c5770e3",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-24T08:22:07.509426Z",
     "start_time": "2025-10-24T08:21:52.848874Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%load_ext tensorboard\n",
    "trainer.fit(writer=writer, model=model, data=train_set, valid=valid_set, use_lr_scheduler=True)"
   ],
   "id": "b36a6467fb7ddf76",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0\n",
      "Training:\n",
      "torch.Size([32, 2])\n",
      "torch.Size([32])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Boolean value of Tensor with more than one value is ambiguous",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mRuntimeError\u001B[39m                              Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[4]\u001B[39m\u001B[32m, line 2\u001B[39m\n\u001B[32m      1\u001B[39m get_ipython().run_line_magic(\u001B[33m'\u001B[39m\u001B[33mload_ext\u001B[39m\u001B[33m'\u001B[39m, \u001B[33m'\u001B[39m\u001B[33mtensorboard\u001B[39m\u001B[33m'\u001B[39m)\n\u001B[32m----> \u001B[39m\u001B[32m2\u001B[39m \u001B[43mtrainer\u001B[49m\u001B[43m.\u001B[49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mwriter\u001B[49m\u001B[43m=\u001B[49m\u001B[43mwriter\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtrain_set\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalid\u001B[49m\u001B[43m=\u001B[49m\u001B[43mvalid_set\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43muse_lr_scheduler\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Documents\\Uni\\2025\\Semester 2\\ICT303\\Assignments\\Assignment 2\\ICT303-Assignment-2\\Trainer.py:44\u001B[39m, in \u001B[36mTrainer.fit\u001B[39m\u001B[34m(self, writer, model, data, valid, resume, completed_epochs, use_lr_scheduler)\u001B[39m\n\u001B[32m     42\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[33mTraining:\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m     43\u001B[39m \u001B[38;5;28mself\u001B[39m.model.train()\n\u001B[32m---> \u001B[39m\u001B[32m44\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mfit_epoch\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     46\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[33mValidating:\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m     47\u001B[39m \u001B[38;5;28mself\u001B[39m.model.eval()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Documents\\Uni\\2025\\Semester 2\\ICT303\\Assignments\\Assignment 2\\ICT303-Assignment-2\\Trainer.py:86\u001B[39m, in \u001B[36mTrainer.fit_epoch\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m     83\u001B[39m \u001B[38;5;28mprint\u001B[39m(target.shape)\n\u001B[32m     85\u001B[39m \u001B[38;5;66;03m# get loss for the predicted output\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m86\u001B[39m loss = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m.\u001B[49m\u001B[43mloss\u001B[49m\u001B[43m(\u001B[49m\u001B[43my_hat\u001B[49m\u001B[43m=\u001B[49m\u001B[43moutputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtarget\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     88\u001B[39m \u001B[38;5;66;03m# get gradients w.r.t the parameters of the model\u001B[39;00m\n\u001B[32m     89\u001B[39m loss.backward()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Documents\\Uni\\2025\\Semester 2\\ICT303\\Assignments\\Assignment 2\\ICT303-Assignment-2\\CNN.py:34\u001B[39m, in \u001B[36mCNN.loss\u001B[39m\u001B[34m(y_hat, y)\u001B[39m\n\u001B[32m     31\u001B[39m \u001B[38;5;129m@staticmethod\u001B[39m\n\u001B[32m     32\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mloss\u001B[39m(y_hat, y):\n\u001B[32m     33\u001B[39m     fn = nn.BCEWithLogitsLoss\n\u001B[32m---> \u001B[39m\u001B[32m34\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[43my_hat\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Documents\\Uni\\2025\\Semester 2\\ICT303\\Assignments\\Assignment 2\\ICT303-Assignment-2\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:821\u001B[39m, in \u001B[36mBCEWithLogitsLoss.__init__\u001B[39m\u001B[34m(self, weight, size_average, reduce, reduction, pos_weight)\u001B[39m\n\u001B[32m    813\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m__init__\u001B[39m(\n\u001B[32m    814\u001B[39m     \u001B[38;5;28mself\u001B[39m,\n\u001B[32m    815\u001B[39m     weight: Optional[Tensor] = \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[32m   (...)\u001B[39m\u001B[32m    819\u001B[39m     pos_weight: Optional[Tensor] = \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[32m    820\u001B[39m ) -> \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m821\u001B[39m     \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[34;43m__init__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43msize_average\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreduce\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreduction\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    822\u001B[39m     \u001B[38;5;28mself\u001B[39m.register_buffer(\u001B[33m\"\u001B[39m\u001B[33mweight\u001B[39m\u001B[33m\"\u001B[39m, weight)\n\u001B[32m    823\u001B[39m     \u001B[38;5;28mself\u001B[39m.register_buffer(\u001B[33m\"\u001B[39m\u001B[33mpos_weight\u001B[39m\u001B[33m\"\u001B[39m, pos_weight)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Documents\\Uni\\2025\\Semester 2\\ICT303\\Assignments\\Assignment 2\\ICT303-Assignment-2\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:44\u001B[39m, in \u001B[36m_Loss.__init__\u001B[39m\u001B[34m(self, size_average, reduce, reduction)\u001B[39m\n\u001B[32m     42\u001B[39m \u001B[38;5;28msuper\u001B[39m().\u001B[34m__init__\u001B[39m()\n\u001B[32m     43\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m size_average \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mor\u001B[39;00m reduce \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m---> \u001B[39m\u001B[32m44\u001B[39m     \u001B[38;5;28mself\u001B[39m.reduction: \u001B[38;5;28mstr\u001B[39m = \u001B[43m_Reduction\u001B[49m\u001B[43m.\u001B[49m\u001B[43mlegacy_get_string\u001B[49m\u001B[43m(\u001B[49m\u001B[43msize_average\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreduce\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     45\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m     46\u001B[39m     \u001B[38;5;28mself\u001B[39m.reduction = reduction\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Documents\\Uni\\2025\\Semester 2\\ICT303\\Assignments\\Assignment 2\\ICT303-Assignment-2\\.venv\\Lib\\site-packages\\torch\\nn\\_reduction.py:44\u001B[39m, in \u001B[36mlegacy_get_string\u001B[39m\u001B[34m(size_average, reduce, emit_warning)\u001B[39m\n\u001B[32m     41\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m reduce \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m     42\u001B[39m     reduce = \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m44\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m size_average \u001B[38;5;129;01mand\u001B[39;00m reduce:\n\u001B[32m     45\u001B[39m     ret = \u001B[33m\"\u001B[39m\u001B[33mmean\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m     46\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m reduce:\n",
      "\u001B[31mRuntimeError\u001B[39m: Boolean value of Tensor with more than one value is ambiguous"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.clf()\n",
    "plt.plot(getattr(trainer, \"avg_train_loss\"), label=\"Avg. Training Loss\")\n",
    "plt.plot(getattr(trainer, \"avg_valid_loss\"), label=\"Avg. Validation Loss\")\n",
    "plt.plot(getattr(trainer, \"training_accuracy\"), label=\"Training Accuracy (x100)%\")\n",
    "plt.plot(getattr(trainer, \"validation_accuracy\"), label=\"Validation Accuracy (x100)%\")\n",
    "plt.legend()\n",
    "plt.savefig(os.getcwd() + \"/CNN/CNN_Loss_Plot.jpg\")"
   ],
   "id": "f9b948175372690a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "%tensorboard --logdir=./CNN",
   "id": "2ace5aa7227e2f1f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "classes = train_set.dataset.classes\n",
    "dataiter = iter(test_set)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "images = images.to(device)\n",
    "\n",
    "img_show(torchvision.utils.make_grid(images))\n",
    "model.eval()\n",
    "output = model(images).to(device)\n",
    "estimatedLabels = torch.max(output, 1).indices\n",
    "\n",
    "print('Estimated Labels: ', ' '.join(f'{classes[estimatedLabels[j]]:5s}' for j in range(images.shape[0])))"
   ],
   "id": "ce6d9d6f12f10ddb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "As someone who works in the Fire Detection and Evacuation industry, I thought it would be interesting to train a model that can recognise if there is a fire in a given image. So I've decided to train a model to perform binary classification on images that contain fire or no fire. I decided to do binary classification as it is something I am familiar with, allowing me to focus more on the process with finetuning without worrying too much about how to load and train the model.",
   "id": "d579ad94be4d3301"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "As I already have built a data loader and trainer, and confusion matrix class in the first assignment, I brought that across and made any improvements or adjustments I needed to make. I also installed any libraries I required.",
   "id": "24e01cd4de09b0e8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "I have decided to move the image tranforms out of the data loader, making it a bit more modular by passing in the transformation to use. I also have update the transformation I will use for training by introducing some data augmentation such as random flips, rotation and sharpness. I added the sharpness augmentation to simulate the possibility of coming from low quality images, such as screenshots of CCTV footage or equivalent, allowing this to be applied in real world scenarios.",
   "id": "c9fc55a0ef57761f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Originally I was planning to try to implement a DenseNet architecture to address potential issues with exploding or vanishing gradients, however with the size of the dataset I have chosen, I think it may make the model too complex for the amount of data. So for the size of the dataset, it should require a smaller model. For this reason, I have decided to experiment around with some custom CNN architectures.",
   "id": "8cad4bb87b707a3f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "For my initial architecture, I have decided to use 3 blocks that consist of a convolutional layer, a ReLU activation and a max pool. I use ReLU as the activation function as it is the most commonly used activation function for modern neural networks. For the loss function, I have gone with torch's BCEWithLogitsLoss method. This method applies a Sigmoid activation to the outputs of the network and then calculates the Binary Cross Entropy Loss. According to torch's documentation, this is more stable than applying the Sigmoid manually and then calling BCELoss instead (https://docs.pytorch.org/docs/stable/generated/torch.nn.BCEWithLogitsLoss.html).",
   "id": "67123791d96b20bd"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "An issue I came across early was with my data loader. The dataset I chose didn't come with pre-organised training, validation, and test sets, so I knew I would have to split them myself. Instinctively, I did this in the data loader load method using the random_split method from torch. However, as I thought more deeply about it, I realised that if I needed to reload the dataset to continue training further, or restart training from a previous checkpoint, there would be no guarantees that I would have the same split, potentially causing the model to train with the test data. My solution was to split the dataset manually because of the size not being too large.",
   "id": "a7e3e804376dae9e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "I reorganised the dataset into 3 folders, one for training, one for validation, and one for testing. Inside the images are split into the 2 classes, fire and no fire. I used a 70/20/10 split for training, validation, and testing.",
   "id": "d116aec4b6146994"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
